---
layout: post
published: true
title: 2025-06-17-谈谈我对大模型的理解之训推平台篇
categories: [大模型]
tags: [大模型,训推平台]
---
* content
{:toc}



>我是谁： 我是一名软件工程师，目前在某互联网公司做技术开发。我会将自己所有真实的想法及所掌握的技术，在网上分享。如果支持作者，请点击关注。


在大模型领域，我们会有很多新的名词，每个名词看上去“字”都认识，以为自己懂了；其实往深处想想，会发现自己还是一知半解，尤其在专业领域。因此，为了彻底掌握这些新名词，我写一篇文章 ，目的就是要彻底搞懂它们，如果你对这些名词还不是很熟悉，请参考这篇文章【】

在学习一个新的知识的时候，如果想知道自己是否真的理解，可以问下自己以下三个问题，**是什么、为什么、怎么做**。

你可以以这次的主题**训推平台**为例，闭上眼睛，问下自己上述三个问题，然后尝试自己回答。

> 请停下来，不着急阅读，尝试一下自己回答。希望你能将自己的答案，直接写在留言上。然后再回过头来对比我的回答，看看是否有差异。不断反思、对比、总结、归纳，才能进步与成长。**自己总结出的东西，才能算是自己真正掌握的知识。** 



好了，我们正式开始。这篇文章就是我个人的总结，我会用自己的话，把模型中非常关键的平台-**训推平台**讲清楚。围绕上述三个问题展开，事实上也是我的自问自答。涉及它的定义、用处、做法、开源生态，以及常说的模型训练流水线中的PP/DP/TP是什么。



# 训推平台是什么

在大模型领域，我们向模型提问时，模型会根据自己已经掌握的知识，结合问题本身，给出“通用性”的回答。这好比一位知识渊博的“通才”学生，无所不知；但相比之下，专业领域的学生则个性化更强，在回答专业问题时更能一针见血。


互联网上的通用大语言模型（如豆包、deepseek、通义千问、闻心一言），就是上述所谓的“通才”。但是如果在私有化场景下，他们有两个地方不能满足要求：

- 加载用户私有数据
- 数据安全


**在企业内部，我们面对的是行业中细分领域的专业问题。此时，模型无需“无所不知”，最核心的需求是能够加载企业私有数据，且能保证这些数据的安全不外流。在回答用户问题时，模型能依据企业的生产流程及规范进行分析作答，并且回答内容有明确的限制和边界，绝不泄露敏感信息。**

我们常说的“小模型”或“行业模型”，指的就是这种应用场景下的模型，主要是为了跟当前互联网上的通用大语言模型（如豆包、deepseek、通义千问、闻心一言）进行区分。

在互联网上（如Hugginface/ModelScope模型市场）上有很多开源的模型。

如果要达到上述对行业模型的两个要求，有两种主要做法：

1. **知识库（RAG）**：用户上传自己的数据，这些数据可以随时更新。模型在回答问题时，会首先在知识库中搜索相关信息，将匹配到的数据与用户问题一同传递给大型语言模型（LLM）。LLM随后会进行结构化输出。如果某些数据需要临时调整，我们可以针对特定的问答内容进行数据标注，直接告诉模型在匹配到这些数据后应如何回答；同时，也标注，碰到哪类问题，不要回答，保证安全。

2. **模型微调（Fine-tuning/LoRA）**：在预训练模型基础上，利用特定任务或领域的数据对模型参数进行优化调整，以提升其在该场景下性能的过程。预训练完的模型，已经有了自己的权重和特征值。模型微调就是加载用户的数据，对这个参数进行修正。

>  举例来说，假设我们有一个象棋模型，所谓的训练就是提供一组数据，通过奖励机制告诉模型如何走棋才能达到最优。模型的网络是分层的，每一层都有一个权重，权重越大，该层的影响力越强。每层网络都有其权重值，最终得到一组权重值。通过这组权重值进行计算会得到一个结果，如果这个结果与用户的期望不符，就会产生一个“偏移量”，这个偏移量被称为“特征值”。权重与特征值会影响模型的输出，微调的过程就是使用提供的数据，调整模型的权重与特征值，使模型的回答内容更贴近用户的实现情况，更符合用户的偏好。

模型微调是模型直接对话，输出用户想要的内容。而知识库是基于模型之上，通过封装一层业务逻辑，达到的效果。

对模型进行微调的平台就是我们所说的训推平台。


# 为什么需要训推平台

对于一位专业人士而言，即使没有训推平台，他也知道如何从开源社区下载模型、加载数据、训练模型、部署模型。

然而，这些步骤是繁琐的，如果没有标准化作业流程，出错是必然，每次错误也不一样，效率之低下可想而知。

训推平台就是将这些步骤整合，提供出全流程的作业标准。

在软件领域，云计算已经对软件生态做了分层：

- IaaS: （基础设施即服务）是一种云计算服务模式，通过网络向用户提供虚拟计算资源、存储、网络设备等基础设施，用户可按需租赁并自主管理操作系统、应用程序等上层软件，而底层硬件设施的维护与管理由云服务提供商负责。
- PaaS: （平台即服务）向用户提供完整的软件开发和部署平台，包括操作系统、编程语言运行环境、数据库和 Web 服务器等，用户可通过网络在该平台上开发、测试和部署应用程序，无需管理底层基础设施，仅需关注应用程序的开发与维护。
- SAAS:（软件即服务）是一种云计算服务模式，云服务提供商将应用软件统一部署在云端服务器，用户无需本地安装和维护软件，直接通过网络（如浏览器）按需订阅使用软件功能，按约定付费（如按用户数、使用时长等），且软件的更新、维护和服务器管理均由服务商负责。

在大模型领域，其实就是三层：

*   **算力层**：提供 GPU、DCU、NPU 等计算资源，供模型训练使用。
*   **模型层**：负责模型的训练、推理和部署管理。训推平台的核心功能主要集中在这一层。
*   **应用层**：基于模型提供知识库、智能体、问答助手等应用服务。

但是如果为了延用云计算之前的定义，那就需要把模型层加进去，因此，在之前三层基础上，加一层模型层，就变成了：

- IaaS: 
- PaaS:
- MaaS: 模型即服务
- SaaS:  

训推平台处于模型层，由于它是一个平台，因此它是PaaS层的东西，但是它提供出的能力，确实是MaaS层的内容。如暴露出模型的API访问能力，围绕访问量，就有了Token计费、用户认证等等相关的东西。

训练平台分为四个步骤：

*   **数据集管理**：包括数据导入、清洗、转换、加载和版本管理。
*   **模型管理**：提供模型市场（方便从 Hugging Face/ModelScope 快速导入）和模型版本管理。
*   **模型训练**：执行模型的训练过程，加载模型及数据，对模型参数微调。
*   **模型部署**：将训练好的模型部署上线，提供出API能力。

# 有哪些关键技术

> 这里主要讲的是围绕着训练平台的关键技术，而非大模型整个生态的关键技术。


围绕训推平台主要有三个开源的工具可以选择：

1. **Ray**: Ray 提供了训练、调参、评测、部署的全套流程，通常是业界训推首选的工具。但是Ray的缺点也很明显，对用户专业性要求较高。科研从业者使用较多。



2. **KubeFlow**: Kubeflow 基于 Kubernetes 提供了脚手架，允许各种开源组件在其上进行添加，极大地丰富了开源生态，并方便各个组件独立发展。其优点是灵活性高，组件可自由选择和配置。但缺点是无法做到“开箱即用”。

3. **CubeStudio**:  它弥补了 Kubeflow 的不足，在 Kubeflow 的基础上提供了“开箱即用”的能力。包含了整个的工作流全过程，如数据集管理、模型市场、训练、推理、部署、模型评测等。

因此，如果企业想基于开源能力迅速构建出自己的训推平台，CubeStudio是不二之选。


> 如果对想体验CubeStudio能力，关注账号回复“cubestudio”即可。

# 模型训练中流水线并行

在模型训练时，经常会提到数据并行、模型并行流水线，那它们是什么意思呢？

在模型训练过程中，GPU 的显存是有限的，例如 H20 显卡可以提供 96GB 显存。训练时，模型和数据都需要加载到显存中。然而，如果模型或数据过大，就无法进行训练。

此时，就需要进行切分。我们可以选择对模型进行切分，或者对数据进行切分，将其分配到多个 GPU 中。

*   按模型维度切分: **模型并行（Model Parallelism）**
*   按数据维度切分: **数据并行（Data Parallelism）**

因此围绕着这个场景，就有了三种处理方式：PP、DP、TP。

*  **DP 数据并行**（Data Parallelism）：将模型复制到每个 GPU 上，然后将数据切分后分发给各个 GPU。这种方式适用于模型较小、数据量较大的场景。
*   **PP 流水线并行**（Pipeline Parallelism）：按模型网络层级进行切分。这种方式是串行的，可能会造成 GPU 资源浪费。
*  **TP 张量并行**（Tensor Parallelism）：按模型权重张量进行切分。这种实现方式通常比较复杂。


>我在做什么： 我会将自己所学的知识，用自己的话讲出来，在公众号我会用心写好每篇文章。同时，有些资料不方便公开传播，因此，这部分内容会放在【知识星球】【https://t.zsxq.com/boOEB】，点击原文可以直接跳转。由于星球刚开始做，我设定了个最低价格50元一年，官方也提供了一周免费退订。由于刚开始运营，且刚好碰上618，为了保证大家不吃亏，星球前100名用户，随时支持全款退订。